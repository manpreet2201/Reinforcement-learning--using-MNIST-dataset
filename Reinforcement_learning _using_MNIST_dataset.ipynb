{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of FinalProject-1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppOudt2LgkmX",
        "outputId": "4b27cf34-e7c2-442f-8d96-db5b216f2fb6"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models, layers, optimizers, datasets, utils, losses\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)/255\n",
        "# x_train = x_train[:1024,:,:,:]\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)/255\n",
        "# x_test = x_test[:501,:,:,:]\n",
        "y_train = utils.to_categorical(y_train, 10)\n",
        "y_test = utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4FbwOLZ9t3l"
      },
      "source": [
        "CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5CVYg3k39oI"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "# compile model\n",
        "opt = SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d41sv5D4IC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d939f7be-a550-41c0-d728-d610b4b37a65"
      },
      "source": [
        " model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test), verbose=1)\n",
        "\t\t# evaluate model"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.1632 - accuracy: 0.9498 - val_loss: 0.0684 - val_accuracy: 0.9785\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0557 - accuracy: 0.9829 - val_loss: 0.0491 - val_accuracy: 0.9847\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0367 - accuracy: 0.9888 - val_loss: 0.0441 - val_accuracy: 0.9846\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.0245 - accuracy: 0.9930 - val_loss: 0.0427 - val_accuracy: 0.9851\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.0469 - val_accuracy: 0.9857\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.0406 - val_accuracy: 0.9875\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 0.0418 - val_accuracy: 0.9866\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.0421 - val_accuracy: 0.9871\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0439 - val_accuracy: 0.9870\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0439 - val_accuracy: 0.9871\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f475c5c32b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmlKt-cq4K2k",
        "outputId": "dfe74652-2d6e-4794-aa6a-255059cb82a8"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.043854448944330215\n",
            "Test accuracy: 0.9871000051498413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0d_-dV39wTF"
      },
      "source": [
        "Freezing all Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lQGVN2I4hMl"
      },
      "source": [
        "# freezing \n",
        "for layer in model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpmmNfrm90d4"
      },
      "source": [
        "RL Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5S5o-aE4mDn"
      },
      "source": [
        "numInput = model.output\n",
        "h = layers.Dense(20, activation='relu')(numInput)\n",
        "outputs = layers.Dense(2, activation='linear')(h)\n",
        "\n",
        "model_rl = models.Model(inputs=model.inputs, outputs=[outputs,numInput])\n",
        "RMSprop = optimizers.RMSprop(lr=0.01)\n",
        "model_rl.compile(loss='mse', optimizer=RMSprop)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmmPPMgN4PtB"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models, layers, optimizers\n",
        "\n",
        "def tau(trial,s,a):\n",
        "    numOut= model_rl.predict(s)\n",
        "    argM = np.argmax(numOut[1])\n",
        "    hotEncoding= utils.to_categorical(argM, 10)\n",
        "    if (hotEncoding[0] and hotEncoding[9]) == 0 : s=x_train[trial+a,:].reshape(1,28, 28, 1)\n",
        "    return s\n",
        "\n",
        "def rho(s):\n",
        "    numOut= model_rl.predict(s)\n",
        "    argM = np.argmax(numOut[1])\n",
        "    hotEncoding= utils.to_categorical(argM, 10)\n",
        "    return ((hotEncoding[0]==1)+2*(hotEncoding[9]==1))\n",
        "\n",
        "def terminal_state(s):\n",
        "  numOut= model_rl.predict(s)\n",
        "  argM = np.argmax(numOut[1])\n",
        "  hotEncoding= utils.to_categorical(argM, 10)\n",
        "  return (hotEncoding[0]==1 or hotEncoding[9]==1)    \n",
        "\n",
        "gamma=0.8\n",
        "invT = 0.8"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiILxQDg4pVH"
      },
      "source": [
        "for trial in range(1000):\n",
        "    s = x_train[trial,:].reshape(1,28, 28, 1)\n",
        "    #for t in range(0,10):\n",
        "    if terminal_state(s): \n",
        "      break\n",
        "    if trial > 1000 and invT > 0.1: invT -= 0.001\n",
        "    prediction=model_rl.predict(s, steps=1, verbose=0)[0]\n",
        "    aidx=np.argmax(prediction)\n",
        "    if np.random.rand() < invT : aidx=1-aidx\n",
        "    a=2*aidx-1\n",
        "    next_s = tau(trial,s,a)\n",
        "    if terminal_state(next_s): \n",
        "        y = rho(next_s)\n",
        "    else:\n",
        "        y = gamma*np.max(model_rl.predict(next_s, steps=1, verbose=0)[0])\n",
        "    prediction[0,aidx]=y\n",
        "    next_numOut= model_rl.predict(next_s, steps=1, verbose=0)[1]\n",
        "    next_argM = np.argmax(next_numOut)\n",
        "    next_hotEncoding= utils.to_categorical(next_argM, 10)\n",
        "    predictionList = []\n",
        "    predictionList.append(prediction.reshape(1,2))\n",
        "    predictionList.append(next_hotEncoding.reshape(1,10))\n",
        "    model_rl.fit(s, predictionList, epochs=1, verbose=0)\n",
        "    s = np.copy(next_s)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nUxVAwVMLAw",
        "outputId": "39209957-499c-4e69-a90a-e3e44e62d595"
      },
      "source": [
        "policy = np.zeros(101)\n",
        "Q=[]\n",
        "for i in range(0,101):\n",
        "  s = x_test[i,:].reshape(1,28, 28, 1)\n",
        "  Qs=model_rl.predict(s, steps=1)[0]\n",
        "  Q.append(Qs)\n",
        "  aidx=np.argmax(Qs)\n",
        "  policy[i]=2*aidx-1\n",
        "    # s = np.roll(s,1)\n",
        "print(np.transpose(Q))\n",
        "print('policy:',np.transpose(policy))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[-0.22287118 -0.09293188  0.3947956  -0.20899694 -0.22633582\n",
            "    0.39479765 -0.22633016 -0.09460001  0.02792939 -0.09460045\n",
            "   -0.20899698  0.00626943 -0.09460019 -0.20899698  0.3948032\n",
            "    0.02768115 -0.09460022 -0.22287118  0.15697539 -0.22633594\n",
            "   -0.09460729  0.00626355  0.00626942  0.02768286 -0.22633457\n",
            "   -0.20899698 -0.2228716  -0.22633594 -0.20899698  0.3947934\n",
            "    0.16318549  0.3945507   0.16318549 -0.22636156 -0.22287117\n",
            "   -0.09293188 -0.22285768  0.39479998 -0.09293188  0.3948018\n",
            "    0.39479783 -0.22287111 -0.2263346  -0.09292728  0.16318135\n",
            "    0.02768286  0.39478922 -0.09293188 -0.22633547 -0.22633594\n",
            "    0.00626937  0.16318549  0.02768284  0.02768259  0.00626943\n",
            "   -0.20899698 -0.22633594  0.39479917 -0.09460021  0.02758252\n",
            "   -0.22287092  0.19598365 -0.09592002  0.162491   -0.22287117\n",
            "   -0.2263275   0.00626922 -0.2263357   0.16318549 -0.20899698\n",
            "   -0.22287121 -0.20899698 -0.09293185 -0.09462048  0.3948014\n",
            "   -0.22287117  0.16318549 -0.09293006 -0.09458826 -0.222871\n",
            "   -0.22288378  0.00626942 -0.09293188 -0.22287117  0.19599426\n",
            "   -0.22633594 -0.22287118  0.16317981  0.00626943  0.39479834\n",
            "    0.16318549  0.00626939 -0.16960989  0.16317993  0.39458084\n",
            "   -0.2263321   0.3774812  -0.22287117  0.00626645 -0.09460021\n",
            "    0.00626943]]\n",
            "\n",
            " [[ 0.11148318  0.09105429  0.14733371  0.28065416  0.18449087\n",
            "    0.14733092  0.18448886 -0.16231945  0.5105159  -0.16231774\n",
            "    0.28065422  0.24730176 -0.16231751  0.28065422  0.14733393\n",
            "    0.5109866  -0.16231748  0.11148318  0.44156945  0.18449116\n",
            "   -0.16231683  0.2473097   0.24730176  0.5109872   0.18448682\n",
            "    0.28065422  0.11148294  0.18449116  0.28065422  0.1473357\n",
            "    0.56653106  0.14731668  0.56653106  0.18443641  0.11148318\n",
            "    0.09105429  0.11148052  0.14733352  0.09105428  0.1473341\n",
            "    0.14733148  0.11148314  0.18448788  0.09105186  0.56653064\n",
            "    0.5109872   0.14733057  0.09105429  0.18449     0.18449116\n",
            "    0.24730182  0.56653106  0.51098716  0.51098716  0.24730176\n",
            "    0.28065422  0.18449116  0.14733195 -0.16231751  0.51063687\n",
            "    0.1114832  -0.00187391 -0.15756434  0.5635999   0.11148318\n",
            "    0.18447036  0.24730147  0.1844906   0.56653106  0.28065422\n",
            "    0.11148318  0.28065422  0.09105428 -0.16230957  0.14733401\n",
            "    0.11148318  0.56653106  0.09105328 -0.16231672  0.11148298\n",
            "    0.11147492  0.24730176  0.09105429  0.11148318 -0.00187353\n",
            "    0.18449116  0.11148318  0.56652296  0.24730176  0.1473325\n",
            "    0.56653106  0.24730179 -0.13746528  0.56651163  0.14737572\n",
            "    0.18448853  0.13331427  0.11148318  0.24729864 -0.1623175\n",
            "    0.24730176]]]\n",
            "policy: [ 1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1.\n",
            "  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1.  1.  1.\n",
            "  1. -1.  1. -1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1. -1. -1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1. -1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1. -1.\n",
            "  1.  1.  1.  1. -1.  1. -1.  1.  1. -1.  1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNh7fIZr9-0P"
      },
      "source": [
        "Freezing first 3 layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0OZiIz3D9OG",
        "outputId": "f2a1f21f-c756-4abf-efe3-f96c442b84cc"
      },
      "source": [
        "for i, layer in enumerate(model.layers):\n",
        "   print(i, layer.name)\n",
        "\n",
        "for layer in model.layers[:4]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[4:]:\n",
        "   layer.trainable = True"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 conv2d_4\n",
            "1 max_pooling2d_4\n",
            "2 flatten_4\n",
            "3 dense_10\n",
            "4 dense_11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFGL0XAmNHnT"
      },
      "source": [
        "numInput = model.output\n",
        "h = layers.Dense(20, activation='relu')(numInput)\n",
        "outputs = layers.Dense(2, activation='linear')(h)\n",
        "\n",
        "model_rl = models.Model(inputs=model.inputs, outputs=[outputs,numInput])\n",
        "RMSprop = optimizers.RMSprop(lr=0.01)\n",
        "model_rl.compile(loss='mse', optimizer=RMSprop)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCJvoWYdHuo8"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models, layers, optimizers\n",
        "\n",
        "def tau(trial,s,a):\n",
        "    numOut= model_rl.predict(s)\n",
        "    argM = np.argmax(numOut[1])\n",
        "    hotEncoding= utils.to_categorical(argM, 10)\n",
        "    if (hotEncoding[0] and hotEncoding[9]) == 0 : s=x_train[trial+a,:].reshape(1,28, 28, 1)\n",
        "    return s\n",
        "\n",
        "def rho(s):\n",
        "    numOut= model_rl.predict(s)\n",
        "    argM = np.argmax(numOut[1])\n",
        "    hotEncoding= utils.to_categorical(argM, 10)\n",
        "    return ((hotEncoding[0]==1)+2*(hotEncoding[9]==1))\n",
        "\n",
        "def terminal_state(s):\n",
        "  numOut= model_rl.predict(s)\n",
        "  argM = np.argmax(numOut[1])\n",
        "  hotEncoding= utils.to_categorical(argM, 10)\n",
        "  return (hotEncoding[0]==1 or hotEncoding[9]==1)    \n",
        "\n",
        "gamma=0.8\n",
        "invT = 0.8"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5FuTjiJHy8p"
      },
      "source": [
        "for trial in range(400):\n",
        "    s = x_train[trial,:].reshape(1,28, 28, 1)\n",
        "   \n",
        "    if terminal_state(s): \n",
        "      break\n",
        "    if trial > 1000 and invT > 0.1: invT -= 0.001\n",
        "    prediction=model_rl.predict(s, steps=1, verbose=0)[0]\n",
        "    aidx=np.argmax(prediction)\n",
        "    if np.random.rand() < invT : aidx=1-aidx\n",
        "    a=2*aidx-1\n",
        "    next_s = tau(trial,s,a)\n",
        "    if terminal_state(next_s): \n",
        "        y = rho(next_s)\n",
        "    else:\n",
        "        y = gamma*np.max(model_rl.predict(next_s, steps=1, verbose=0)[0])\n",
        "        trial= trial+a\n",
        "    prediction[0,aidx]=y\n",
        "    next_numOut= model_rl.predict(next_s, steps=1, verbose=0)[1]\n",
        "    next_argM = np.argmax(next_numOut)\n",
        "    next_hotEncoding= utils.to_categorical(next_argM, 10)\n",
        "    predictionList = []\n",
        "    predictionList.append(prediction.reshape(1,2))\n",
        "    predictionList.append(next_hotEncoding.reshape(1,10))\n",
        "    model_rl.fit(s, predictionList, epochs=1, verbose=0)\n",
        "    s = np.copy(next_s)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AuNA3k7H2X0",
        "outputId": "c73343aa-58fa-43f3-c0cd-b67589cd0200"
      },
      "source": [
        "policy = np.zeros(101)\n",
        "Q=[]\n",
        "for i in range(0,101):\n",
        "  s = x_test[i,:].reshape(1,28, 28, 1)\n",
        "  Qs=model_rl.predict(s, steps=1)[0]\n",
        "  Q.append(Qs)\n",
        "  aidx=np.argmax(Qs)\n",
        "  policy[i]=2*aidx-1\n",
        "    # s = np.roll(s,1)\n",
        "print(np.transpose(Q))\n",
        "print('policy:',np.transpose(policy))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 0.11923891  0.12339538  0.140427   -0.02715863  0.09707148\n",
            "    0.14042516  0.09706937 -0.02398691  0.255263   -0.02398761\n",
            "   -0.02715859  0.32909346 -0.02398789 -0.02715861  0.14042673\n",
            "    0.25502348 -0.0239878   0.11923891  0.01547405  0.09707162\n",
            "   -0.02398371  0.32909125  0.32909343  0.2550246   0.09706973\n",
            "   -0.02715859  0.1192386   0.09707162 -0.02715859  0.14042811\n",
            "    0.03407424  0.14040288  0.03407425  0.09699713  0.11923891\n",
            "    0.12339538  0.11924632  0.14042662  0.12339541  0.14042692\n",
            "    0.14042604  0.11923902  0.09707001  0.12339769  0.03407716\n",
            "    0.2550246   0.14042854  0.12339538  0.09707104  0.09707162\n",
            "    0.3290935   0.03407424  0.25502458  0.25502443  0.32909346\n",
            "   -0.02715859  0.09707162  0.14042588 -0.0239879   0.2550424\n",
            "    0.11923966  0.27830437 -0.02134241  0.03365729  0.11923891\n",
            "    0.0970615   0.32909325  0.09707136  0.03407424 -0.02715859\n",
            "    0.1192389  -0.02715859  0.1233954  -0.02396581  0.14042695\n",
            "    0.11923891  0.03407424  0.12339613 -0.02392989  0.11923897\n",
            "    0.11922874  0.32909346  0.12339538  0.11923891  0.27830622\n",
            "    0.09707162  0.11923896  0.03407339  0.32909346  0.14042693\n",
            "    0.03407424  0.32909346 -0.01172563  0.03406579  0.14046104\n",
            "    0.09706967  0.12548697  0.11923893  0.32908976 -0.02398789\n",
            "    0.32909346]]\n",
            "\n",
            " [[-0.10752978  0.07027603  0.11532145 -0.04152896  0.09746493\n",
            "    0.11531746  0.09746608  0.00597241  0.28009892  0.00596996\n",
            "   -0.04152898 -0.07750233  0.0059699  -0.04152898  0.11532003\n",
            "    0.28022894  0.00596988 -0.10752978  0.12218295  0.09746493\n",
            "    0.00596299 -0.07748456 -0.07750233  0.28023037  0.09746502\n",
            "   -0.04152898 -0.10753006  0.09746493 -0.04152898  0.11532416\n",
            "    0.11457348  0.11539607  0.11457348  0.09742061 -0.10752978\n",
            "    0.07027603 -0.10750443  0.1153205   0.07027603  0.11532053\n",
            "    0.11532038 -0.1075295   0.09746506  0.07028005  0.11457563\n",
            "    0.28023037  0.11532867  0.07027603  0.09746496  0.09746493\n",
            "   -0.07750215  0.11457348  0.28023034  0.28023016 -0.07750233\n",
            "   -0.04152898  0.09746493  0.11531886  0.00596986  0.2801131\n",
            "   -0.10752675  0.22943312  0.00660468  0.11421894 -0.10752978\n",
            "    0.0974658  -0.07750215  0.09746499  0.11457348 -0.04152898\n",
            "   -0.10752978 -0.04152898  0.07027603  0.00595346  0.11532056\n",
            "   -0.10752978  0.11457348  0.07027745  0.00603081 -0.10752925\n",
            "   -0.10753859 -0.07750234  0.07027603 -0.10752978  0.229432\n",
            "    0.09746493 -0.10752973  0.11457187 -0.07750233  0.1153213\n",
            "    0.11457348 -0.07750227  0.12540501  0.11457057  0.11541484\n",
            "    0.09746565  0.11514341 -0.10752978 -0.07749847  0.00596987\n",
            "   -0.07750233]]]\n",
            "policy: [-1. -1. -1. -1.  1. -1.  1.  1.  1.  1. -1. -1.  1. -1. -1.  1.  1. -1.\n",
            "  1.  1.  1. -1. -1.  1.  1. -1. -1.  1. -1. -1.  1. -1.  1.  1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1. -1.  1.  1. -1.  1.  1.  1.\n",
            " -1. -1.  1. -1.  1.  1. -1. -1.  1.  1. -1.  1. -1.  1.  1. -1. -1. -1.\n",
            " -1.  1. -1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1.  1. -1.  1. -1. -1.\n",
            "  1. -1.  1.  1. -1.  1. -1. -1. -1.  1. -1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGDkNbYCv_BE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_ImBSQYv7P7"
      },
      "source": [
        "Part 2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti38zOlqPPQ1"
      },
      "source": [
        "inputs = layers.Input(shape=(28, 28, 1,))\n",
        "x=layers.Conv2D(32, kernel_size=(3, 3),activation='relu')(inputs)\n",
        "x=layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x=layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x=layers.Dropout(0.25)(x)\n",
        "x=layers.Flatten()(x)\n",
        "x=layers.Dense(128, activation='relu')(x)\n",
        "x=layers.Dropout(0.5)(x)\n",
        "numOut=layers.Dense(10, activation='softmax')(x)\n",
        "h = layers.Dense(20, activation='relu')(numOut)\n",
        "outputs = layers.Dense(2, activation='linear')(h)\n",
        "\n",
        "model_RL = models.Model(inputs=inputs, outputs=[outputs,numOut])\n",
        "RMSprop = optimizers.RMSprop(lr=0.01)\n",
        "model_RL.compile(loss='mse', optimizer=RMSprop)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFPNcGouPnwM"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import models, layers, optimizers\n",
        "\n",
        "def tau(trial,s,a):\n",
        "    numOut= model_RL.predict(s)\n",
        "    argM = np.argmax(numOut[1])\n",
        "    hotEncoding= utils.to_categorical(argM, 10)\n",
        "    if (hotEncoding[0] and hotEncoding[9]) == 0 : s=x_train[trial+a,:].reshape(1,28, 28, 1)\n",
        "    return s\n",
        "\n",
        "def rho(s):\n",
        "    numOut= model_rl.predict(s)\n",
        "    argM = np.argmax(numOut[1])\n",
        "    hotEncoding= utils.to_categorical(argM, 10)\n",
        "    return ((hotEncoding[0]==1)+2*(hotEncoding[9]==1))\n",
        "\n",
        "def terminal_state(s):\n",
        "  numOut= model_RL.predict(s)\n",
        "  argM = np.argmax(numOut[1])\n",
        "  hotEncoding= utils.to_categorical(argM, 10)\n",
        "  return (hotEncoding[0]==1 or hotEncoding[9]==1)    \n",
        "\n",
        "gamma=0.8\n",
        "invT = 0.8"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y07pPMZrPu2r"
      },
      "source": [
        "for trial in range(400):\n",
        "    s = x_train[trial,:].reshape(1,28, 28, 1)\n",
        "    if terminal_state(s): \n",
        "      break\n",
        "    if trial > 1000 and invT > 0.1: invT -= 0.001\n",
        "    prediction=model_RL.predict(s, steps=1, verbose=0)[0]\n",
        "    aidx=np.argmax(prediction)\n",
        "    if np.random.rand() < invT : aidx=1-aidx\n",
        "    a=2*aidx-1\n",
        "    next_s = tau(trial,s,a)\n",
        "    if terminal_state(next_s): \n",
        "        y = rho(next_s)\n",
        "    else:\n",
        "        y = gamma*np.max(model_RL.predict(next_s, steps=1, verbose=0)[0])\n",
        "    prediction[0,aidx]=y\n",
        "    next_numOut= model_RL.predict(next_s, steps=1, verbose=0)[1]\n",
        "    next_argM = np.argmax(next_numOut)\n",
        "    next_hotEncoding= utils.to_categorical(next_argM, 10)\n",
        "    predictionList = []\n",
        "    predictionList.append(prediction.reshape(1,2))\n",
        "    predictionList.append(next_hotEncoding.reshape(1,10))\n",
        "    model_RL.fit(s, predictionList, epochs=1, verbose=0)\n",
        "    s = np.copy(next_s)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRBEjU9uP5Vd",
        "outputId": "52764ef7-be9f-4a8c-b6f2-db836cbc38ca"
      },
      "source": [
        "policy = np.zeros(101)\n",
        "Q=[]\n",
        "for i in range(0,101):\n",
        "  s = x_test[i,:].reshape(1,28, 28, 1)\n",
        "  Qs=model_RL.predict(s, steps=1)[0]\n",
        "  Q.append(Qs)\n",
        "  aidx=np.argmax(Qs)\n",
        "  policy[i]=2*aidx-1\n",
        "    # s = np.roll(s,1)\n",
        "print(np.transpose(Q))\n",
        "print('policy:',np.transpose(policy))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0.04073026 0.04073026 0.04073026 0.04073026 0.04073026 0.04073026\n",
            "   0.04073026 0.04073026 0.04073026 0.04073026 0.04073026 0.04073026\n",
            "   0.04073026 0.04073026 0.04073026 0.04073026 0.04073026 0.04073026\n",
            "   0.04073026 0.04073026 0.04073026 0.04073026 0.04073026 0.04073026\n",
            "   0.04073026 0.04073026 0.04073026 0.04073026 0.04073026 0.04073026\n",
            "   0.04073026 0.04073026 0.04073026 0.04073026 0.04073026 0.04073026\n",
            "   0.04073026 0.04073026 0.04073026 0.04073026 0.04073026 0.04073026\n",
            "   0.04073026 0.04073026 0.04073026 0.04073026 0.04073026 0.04073026\n",
            "   0.04073026 0.04073026 0.04073026 0.04073026 0.04073026 0.04073026\n",
            "   0.04073026 0.04073026 0.04073026 0.04073026 0.04073026 0.04073026\n",
            "   0.04073026 0.04073026 0.04073026 0.04073026 0.04073026 0.04073026\n",
            "   0.04073026 0.04073026 0.04073026 0.04073026 0.04073026 0.04073026\n",
            "   0.04073026 0.04073026 0.04073026 0.04073026 0.04073026 0.04073026\n",
            "   0.04073026 0.04073026 0.04073026 0.04073026 0.04073026 0.04073026\n",
            "   0.04073026 0.04073026 0.04073026 0.04073026 0.04073026 0.04073026\n",
            "   0.04073026 0.04073026 0.04073026 0.04073026 0.04073026 0.04073026\n",
            "   0.04073026 0.04073026 0.04073026 0.04073026 0.04073026]]\n",
            "\n",
            " [[0.02767883 0.02767883 0.02767883 0.02767883 0.02767883 0.02767883\n",
            "   0.02767883 0.02767883 0.02767883 0.02767883 0.02767883 0.02767883\n",
            "   0.02767883 0.02767883 0.02767883 0.02767883 0.02767883 0.02767883\n",
            "   0.02767883 0.02767883 0.02767883 0.02767883 0.02767883 0.02767883\n",
            "   0.02767883 0.02767883 0.02767883 0.02767883 0.02767883 0.02767883\n",
            "   0.02767883 0.02767883 0.02767883 0.02767883 0.02767883 0.02767883\n",
            "   0.02767883 0.02767883 0.02767883 0.02767883 0.02767883 0.02767883\n",
            "   0.02767883 0.02767883 0.02767883 0.02767883 0.02767883 0.02767883\n",
            "   0.02767883 0.02767883 0.02767883 0.02767883 0.02767883 0.02767883\n",
            "   0.02767883 0.02767883 0.02767883 0.02767883 0.02767883 0.02767883\n",
            "   0.02767883 0.02767883 0.02767883 0.02767883 0.02767883 0.02767883\n",
            "   0.02767883 0.02767883 0.02767883 0.02767883 0.02767883 0.02767883\n",
            "   0.02767883 0.02767883 0.02767883 0.02767883 0.02767883 0.02767883\n",
            "   0.02767883 0.02767883 0.02767883 0.02767883 0.02767883 0.02767883\n",
            "   0.02767883 0.02767883 0.02767883 0.02767883 0.02767883 0.02767883\n",
            "   0.02767883 0.02767883 0.02767883 0.02767883 0.02767883 0.02767883\n",
            "   0.02767883 0.02767883 0.02767883 0.02767883 0.02767883]]]\n",
            "policy: [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}